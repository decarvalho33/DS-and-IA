# -*- coding: utf-8 -*-
"""projeto_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O7YFszuFJH_OtzfhQqhEOqE4rd1Km00u

# Aula 11

# Setup
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

import statsmodels.api as sm

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression #Regressão Linear
from sklearn.linear_model import LogisticRegression #Regressão Linear
from sklearn import svm #Máquina de Vetor de Suporte
from sklearn.cluster import KMeans

import warnings
warnings.simplefilter(action='ignore')
pd.set_option('display.max_columns', 100)

from google.colab import drive
drive.mount('/content/drive')

"""# Construção da Base"""

activity_codes_mapping = {'A': 'walking',
                          'B': 'jogging',
                          'C': 'stairs',
                          'D': 'sitting',
                          'E': 'standing',
                          'F': 'typing',
                          'G': 'brushing teeth',
                          'H': 'eating soup',
                          'I': 'eating chips',
                          'J': 'eating pasta',
                          'K': 'drinking from cup',
                          'L': 'eating sandwich',
                          'M': 'kicking soccer ball',
                          'O': 'playing catch tennis ball',
                          'P': 'dribbling basket ball',
                          'Q': 'writing',
                          'R': 'clapping',
                          'S': 'folding clothes'}

activity_color_map = {activity_codes_mapping['A']: 'lime',
                      activity_codes_mapping['B']: 'red',
                      activity_codes_mapping['C']: 'blue',
                      activity_codes_mapping['D']: 'orange',
                      activity_codes_mapping['E']: 'yellow',
                      activity_codes_mapping['F']: 'lightgreen',
                      activity_codes_mapping['G']: 'greenyellow',
                      activity_codes_mapping['H']: 'magenta',
                      activity_codes_mapping['I']: 'gold',
                      activity_codes_mapping['J']: 'cyan',
                      activity_codes_mapping['K']: 'purple',
                      activity_codes_mapping['L']: 'lightgreen',
                      activity_codes_mapping['M']: 'violet',
                      activity_codes_mapping['O']: 'limegreen',
                      activity_codes_mapping['P']: 'deepskyblue',   
                      activity_codes_mapping['Q']: 'mediumspringgreen',
                      activity_codes_mapping['R']: 'plum',
                      activity_codes_mapping['S']: 'olive'}
#                     activity_codes_mapping['A']: 'rgb(231, 41, 138)',

features = ['ACTIVITY',
            'X0', # 1st bin fraction of x axis acceleration distribution
            'X1', # 2nd bin fraction ...
            'X2',
            'X3',
            'X4',
            'X5',
            'X6',
            'X7',
            'X8',
            'X9',
            'Y0', # 1st bin fraction of y axis acceleration distribution
            'Y1', # 2nd bin fraction ...
            'Y2',
            'Y3',
            'Y4',
            'Y5',
            'Y6',
            'Y7',
            'Y8',
            'Y9',
            'Z0', # 1st bin fraction of z axis acceleration distribution
            'Z1', # 2nd bin fraction ...
            'Z2',
            'Z3',
            'Z4',
            'Z5',
            'Z6',
            'Z7',
            'Z8',
            'Z9',
            'XAVG', # average sensor value over the window (per axis)
            'YAVG',
            'ZAVG',
            'XPEAK', # Time in milliseconds between the peaks in the wave associated with most activities. heuristically determined (per axis)
            'YPEAK',
            'ZPEAK',
            'XABSOLDEV', # Average absolute difference between the each of the 200 readings and the mean of those values (per axis)
            'YABSOLDEV',
            'ZABSOLDEV',
            'XSTANDDEV', # Standard deviation of the 200 window's values (per axis)  ***BUG!***
            'YSTANDDEV',
            'ZSTANDDEV',
            'XVAR', # Variance of the 200 window's values (per axis)   ***BUG!***
            'YVAR',
            'ZVAR',
            'XMFCC0', # short-term power spectrum of a wave, based on a linear cosine transform of a log power spectrum on a non-linear mel scale of frequency (13 values per axis)
            'XMFCC1',
            'XMFCC2',
            'XMFCC3',
            'XMFCC4',
            'XMFCC5',
            'XMFCC6',
            'XMFCC7',
            'XMFCC8',
            'XMFCC9',
            'XMFCC10',
            'XMFCC11',
            'XMFCC12',
            'YMFCC0', # short-term power spectrum of a wave, based on a linear cosine transform of a log power spectrum on a non-linear mel scale of frequency (13 values per axis)
            'YMFCC1',
            'YMFCC2',
            'YMFCC3',
            'YMFCC4',
            'YMFCC5',
            'YMFCC6',
            'YMFCC7',
            'YMFCC8',
            'YMFCC9',
            'YMFCC10',
            'YMFCC11',
            'YMFCC12',
            'ZMFCC0', # short-term power spectrum of a wave, based on a linear cosine transform of a log power spectrum on a non-linear mel scale of frequency (13 values per axis)
            'ZMFCC1',
            'ZMFCC2',
            'ZMFCC3',
            'ZMFCC4',
            'ZMFCC5',
            'ZMFCC6',
            'ZMFCC7',
            'ZMFCC8',
            'ZMFCC9',
            'ZMFCC10',
            'ZMFCC11',
            'ZMFCC12',
            'XYCOS', # The cosine distances between sensor values for pairs of axes (three pairs of axes)
            'XZCOS',
            'YZCOS',
            'XYCOR', # The correlation between sensor values for pairs of axes (three pairs of axes)
            'XZCOR',
            'YZCOR',
            'RESULTANT', # Average resultant value, computed by squaring each matching x, y, and z value, summing them, taking the square root, and then averaging these values over the 200 readings
            'PARTICIPANT'] # Categirical: 1600 -1650

len(features)

import glob

#the duplicate files to be ignored; all identical to 1600
duplicate_files = [str(i) for i in range(1611, 1618)] # '1611',...'1617'

path = r'/content/drive/MyDrive/Alunos/Aula_11/Data/wisdm-dataset/arff_files/phone/gyro'
all_files_2 = glob.glob('/content/drive/MyDrive/Alunos/Aula_11/Data/wisdm-dataset/arff_files/phone/gyro' + "/*.arff")

list_dfs_phone_gyro = []

for filename in all_files_2:

    if any(dup_fn in filename for dup_fn in duplicate_files):
        continue #ignore the duplicate files
    df_2 = pd.read_csv(filename, names = features, skiprows = 96, index_col=None, header=0)
    list_dfs_phone_gyro.append(df_2)

all_phone_gyro = pd.concat(list_dfs_phone_gyro, axis=0, ignore_index=True, sort=False)

all_phone_gyro

import glob

#the duplicate files to be ignored; all identical to 1600
duplicate_files = [str(i) for i in range(1611, 1618)] # '1611',...'1617'

path = r'/content/drive/MyDrive/Alunos/Aula_11//Data/wisdm-dataset/arff_files/phone/accel'
all_files = glob.glob('/content/drive/MyDrive/Alunos/Aula_11/Data/wisdm-dataset/arff_files/phone/accel' + "/*.arff")

list_dfs_phone_accel = []

for filename in all_files:

    if any(dup_fn in filename for dup_fn in duplicate_files):
        continue #ignore the duplicate files
    df = pd.read_csv(filename, names = features, skiprows = 96, index_col=None, header=0)
    list_dfs_phone_accel.append(df)

all_phone_accel = pd.concat(list_dfs_phone_accel, axis=0, ignore_index=True, sort=False)

all_phone_accel

"""# Redimensionamento da Base"""

cel_acelerometro = all_phone_accel.iloc[:,0:34].merge(all_phone_accel.iloc[:,91:93],
                                                      left_index = True,
                                                      right_index = True,
                                                      how = 'left')

cel_acelerometro

"""# Transformação"""

cel_acelerometro['ACTIVITY'] = np.select([cel_acelerometro['ACTIVITY']=='A',
                                          cel_acelerometro['ACTIVITY']=='B',
                                          cel_acelerometro['ACTIVITY']=='C',
                                          cel_acelerometro['ACTIVITY']=='D',
                                          cel_acelerometro['ACTIVITY']=='E',
                                          cel_acelerometro['ACTIVITY']=='F',
                                          cel_acelerometro['ACTIVITY']=='G',
                                          cel_acelerometro['ACTIVITY']=='H',
                                          cel_acelerometro['ACTIVITY']=='I',
                                          cel_acelerometro['ACTIVITY']=='J',
                                          cel_acelerometro['ACTIVITY']=='K',
                                          cel_acelerometro['ACTIVITY']=='L',
                                          cel_acelerometro['ACTIVITY']=='M',
                                          cel_acelerometro['ACTIVITY']=='O',
                                          cel_acelerometro['ACTIVITY']=='P',
                                          cel_acelerometro['ACTIVITY']=='Q',
                                          cel_acelerometro['ACTIVITY']=='R',
                                          cel_acelerometro['ACTIVITY']=='S'],
                                          ['andar','correr','escadas','sentado','em_pe','digitando','escovando_dentes','tomando_sopa',
                                          'comendo_fritas','comendo_massa','bebendo_copo','comendo_lanche','chutando_bola',
                                           'jogando_bola_tenis',
                                          'driblando_basquete','escrevendo','aplaudindo','dobrando_roupas'])

cel_acelerometro

"""# Primeiras Análises Descritivas"""

all_phone_accel['ACTIVITY'].map(activity_codes_mapping).value_counts().plot(kind = 'bar', 
                                                                                figsize = (15,5), 
                                                                                color = 'purple',
                                                                                title = 'row count per activity',
                                                                                legend = True,
                                                                                fontsize = 15)

all_phone_accel['PARTICIPANT'].value_counts().plot(kind = 'bar',
                                                   figsize = (15,5),
                                                   color = 'orange',
                                                   title= 'rows count per participant',
                                                   legend = True,
                                                   fontsize = 15)

plt.subplots(figsize=(30,5))
tempos = ['X0', 'X1', 'X2', 'X3', 'X4', 'X5',	'X6',	'X7',	'X8',	'X9']

sns.boxplot(x = cel_acelerometro[cel_acelerometro['ACTIVITY']=='andar']['PARTICIPANT'],
            y = 'XAVG',
            data = cel_acelerometro)

plt.subplots(figsize=(30,5))
sns.boxplot(x = cel_acelerometro[cel_acelerometro['ACTIVITY']=='driblando_basquete']['PARTICIPANT'],
            y = 'XAVG',
            data = cel_acelerometro)

plt.subplots(figsize=(30,5))
sns.boxplot(x = cel_acelerometro[cel_acelerometro['ACTIVITY']=='driblando_basquete']['PARTICIPANT'],
            y = 'YAVG',
            data = cel_acelerometro)

plt.subplots(figsize=(30,5))
sns.boxplot(x = cel_acelerometro[cel_acelerometro['ACTIVITY']=='driblando_basquete']['PARTICIPANT'],
            y = 'ZAVG',
            data = cel_acelerometro)

cel_acelerometro[cel_acelerometro['ACTIVITY']=='driblando_basquete'].iloc[:,1:11].hist(figsize=(13,10))
plt.show()

"""#IA """

X = cel_acelerometro.drop(columns=['ACTIVITY','PARTICIPANT'])
y = cel_acelerometro[['ACTIVITY']]

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13, test_size = 0.2)

"""#Regressão Logística"""

